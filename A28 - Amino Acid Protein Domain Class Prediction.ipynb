{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amino acid sequence of protein domain - class prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem description\n",
    "This directory contains data to train a model to predict the function of protein domains, based on the PFam dataset.\n",
    "\n",
    "Domains are functional sub-parts of proteins; much like images in ImageNet are pre segmented to contain exactly one object class, this data is presegmented to contain exactly and only one domain.\n",
    "\n",
    "The purpose of the dataset is to repose the PFam seed dataset as a multiclass classification machine learning task.\n",
    "\n",
    "The task is: given the amino acid sequence of the protein domain, predict which class it belongs to. There are about 1 million training examples, and 18,000 output classes.\n",
    "\n",
    "### Data structure\n",
    "This data is more completely described by the publication \"Can Deep Learning Classify the Protein Universe\", Bileschi et al.\n",
    "\n",
    "#### Data split and layout\n",
    "The approach used to partition the data into training/dev/testing folds is a random split.\n",
    "\n",
    "Training data should be used to train your models.\n",
    "Dev (development) data should be used in a close validation loop (maybe for hyperparameter tuning or model validation).\n",
    "Test data should be reserved for much less frequent evaluations - this helps avoid overfitting on your test data, as it should only be used infrequently.\n",
    "#### File content\n",
    "Each fold (train, dev, test) has a number of files in it. Each of those files contains csv on each line, which has the following fields:\n",
    "\n",
    "sequence: HWLQMRDSMNTYNNMVNRCFATCIRSFQEKKVNAEEMDCTKRCVTKFVGYSQRVALRFAE \n",
    "family_accession: PF02953.15\n",
    "sequence_name: C5K6N5_PERM5/28-87\n",
    "aligned_sequence: ....HWLQMRDSMNTYNNMVNRCFATCI...........RS.F....QEKKVNAEE.....MDCT....KRCVTKFVGYSQRVALRFAE \n",
    "family_id: zf-Tim10_DDP\n",
    "Description of fields: - sequence: These are usually the input features to your model. Amino acid sequence for this domain. There are 20 very common amino acids (frequency > 1,000,000), and 4 amino acids that are quite uncommon: X, U, B, O, Z. - family_accession: These are usually the labels for your model. Accession number in form PFxxxxx.y (Pfam), where xxxxx is the family accession, and y is the version number. Some values of y are greater than ten, and so 'y' has two digits. - family_id: One word name for family. - sequence_name: Sequence name, in the form \"$uniprot_accession_id/$start_index-$end_index\". - aligned_sequence: Contains a single sequence from the multiple sequence alignment (with the rest of the members of the family in seed, with gaps retained.\n",
    "\n",
    "Generally, the family_accession field is the label, and the sequence (or aligned sequence) is the training feature.\n",
    "\n",
    "This sequence corresponds to a domain, not a full protein.\n",
    "\n",
    "The contents of these fields is the same as to the data provided in Stockholm format by PFam at ftp://ftp.ebi.ac.uk/pub/databases/Pfam/releases/Pfam32.0/Pfam-A.seed.gz\n",
    "\n",
    "[1] Eddy, Sean R. \"Accelerated profile HMM searches.\" PLoS computational biology 7.10 (2011): e1002195.\n",
    "\n",
    "#### Reference: https://www.kaggle.com/googleai/pfam-seed-random-split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning Task:\n",
    "* Multiclass classification problem for amino acid sequence of the protein domain, predict which class it belongs to.\n",
    "* Classes can be extracted from family_accession field\n",
    "* Training data can be obtained from sequence. These are usually the input features to your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fcccdc8287eea556a3f10288fea170fe5e214c44"
   },
   "source": [
    "## **SOLUTION**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "966e3c71928f7f67841375c42fa075165883ed01"
   },
   "source": [
    "## Importing required lib's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "4e0ca4c226e616eab8ca6a3a4f3e4fb81f057644"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "from os import listdir\n",
    "from tqdm import tqdm\n",
    "#Supress scientific notation\n",
    "pd.options.display.float_format = '{:20,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e3657e5b60098d2f2d806eabb584bc4226894ed6"
   },
   "source": [
    "### Defining Pretty Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "18880f23376c249996e50989aec42cb62e8cbf6d"
   },
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "model_pretty_table = PrettyTable()\n",
    "model_pretty_table.field_names = [\"Model\",\"Test Score\",\"Test Accuracy\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining all training files to one file, the same for dev and test datasets\n",
    "* Data Source: https://www.kaggle.com/googleai/pfam-seed-random-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndir_ = \"random_split/train\"\\nfilepaths = [f for f in listdir(dir_)] # if f.endswith(\\'.csv\\')]\\npd.concat(map(pd.read_csv, [dir_ + \\'/\\' + s for s in filepaths])).to_csv(\"train.csv\", index=False)\\n\\ndir_ = \"random_split/dev\"\\nfilepaths = [f for f in listdir(dir_)] # if f.endswith(\\'.csv\\')]\\npd.concat(map(pd.read_csv, [dir_ + \\'/\\' + s for s in filepaths])).to_csv(\"dev.csv\", index=False)\\n\\ndir_ = \"random_split/test\"\\nfilepaths = [f for f in listdir(dir_)] # if f.endswith(\\'.csv\\')]\\npd.concat(map(pd.read_csv, [dir_ + \\'/\\' + s for s in filepaths])).to_csv(\"test.csv\", index=False)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "dir_ = \"random_split/train\"\n",
    "filepaths = [f for f in listdir(dir_)] # if f.endswith('.csv')]\n",
    "pd.concat(map(pd.read_csv, [dir_ + '/' + s for s in filepaths])).to_csv(\"train.csv\", index=False)\n",
    "\n",
    "dir_ = \"random_split/dev\"\n",
    "filepaths = [f for f in listdir(dir_)] # if f.endswith('.csv')]\n",
    "pd.concat(map(pd.read_csv, [dir_ + '/' + s for s in filepaths])).to_csv(\"dev.csv\", index=False)\n",
    "\n",
    "dir_ = \"random_split/test\"\n",
    "filepaths = [f for f in listdir(dir_)] # if f.endswith('.csv')]\n",
    "pd.concat(map(pd.read_csv, [dir_ + '/' + s for s in filepaths])).to_csv(\"test.csv\", index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train:  (100000, 5)\n",
      "df_dev  :  (10000, 5)\n",
      "df_test :  (10000, 5)\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"../input/train.csv\")[0:100000]\n",
    "df_dev = pd.read_csv(\"../input/dev.csv\")[0:10000]\n",
    "df_test = pd.read_csv(\"../input/test.csv\")[0:10000]\n",
    "print(\"df_train: \", df_train.shape)\n",
    "print(\"df_dev  : \", df_dev.shape)\n",
    "print(\"df_test : \", df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### number of classes in train, dev, test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique number of classes across train set:  13405\n",
      "Unique number of classes across dev set  :  4921\n",
      "Unique number of classes across test set :  4934\n",
      "Unique number of classes across all sets :  13666\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique number of classes across train set: \", len(np.unique(df_train.family_accession)))\n",
    "print(\"Unique number of classes across dev set  : \", len(np.unique(df_dev.family_accession)))\n",
    "print(\"Unique number of classes across test set : \", len(np.unique(df_test.family_accession)))\n",
    "print(\"Unique number of classes across all sets : \", len (np.union1d( np.union1d(df_train.family_accession, df_dev.family_accession) , df_test.family_accession) ))\n",
    "number_of_unique_classes = len (np.union1d( np.union1d(df_train.family_accession, df_dev.family_accession) , df_test.family_accession) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### common number of classes across sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2884"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = np.intersect1d( np.intersect1d(df_train.family_accession, df_dev.family_accession) , df_test.family_accession)\n",
    "number_of_unique_classes = len (classes)\n",
    "number_of_unique_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train:  (58223, 6)\n",
      "df_dev  :  (7341, 6)\n",
      "df_test :  (7352, 6)\n"
     ]
    }
   ],
   "source": [
    "df_train = df_train.loc[df_train.family_accession.isin(classes)].reset_index()\n",
    "df_dev   = df_dev  .loc[df_dev  .family_accession.isin(classes)].reset_index()\n",
    "df_test  = df_test .loc[df_test .family_accession.isin(classes)].reset_index()\n",
    "print(\"df_train: \", df_train.shape)\n",
    "print(\"df_dev  : \", df_dev.shape)\n",
    "print(\"df_test : \", df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\na4_dims = (20, 4)\\nsns.set(style=\"darkgrid\")\\nax = sns.countplot(x=\"family_accession\", data=df_train)\\nplt.show()\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "a4_dims = (20, 4)\n",
    "sns.set(style=\"darkgrid\")\n",
    "ax = sns.countplot(x=\"family_accession\", data=df_train)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>family_id</th>\n",
       "      <th>sequence_name</th>\n",
       "      <th>family_accession</th>\n",
       "      <th>aligned_sequence</th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GMC_oxred_C</td>\n",
       "      <td>A4WZS5_RHOS5/416-539</td>\n",
       "      <td>PF05199.13</td>\n",
       "      <td>PHPE.SRIRLST.RRDAHGMP.....IP.RIESRLGP............</td>\n",
       "      <td>PHPESRIRLSTRRDAHGMPIPRIESRLGPDAFARLRFMARTCRAIL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Asp_decarbox</td>\n",
       "      <td>X2GQZ4_9BACI/1-115</td>\n",
       "      <td>PF02261.16</td>\n",
       "      <td>MLRMMMNSKIHRATVTEADLNYVGSITIDEDILDAVGMLPNEKVHI...</td>\n",
       "      <td>MLRMMMNSKIHRATVTEADLNYVGSITIDEDILDAVGMLPNEKVHI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Filamin</td>\n",
       "      <td>A7SQM3_NEMVE/342-439</td>\n",
       "      <td>PF00630.19</td>\n",
       "      <td>TACPKQ.CTA....RGLG.............LK.AAPVT.QPT..R...</td>\n",
       "      <td>TACPKQCTARGLGLKAAPVTQPTRFVVILNDCHGQPLGRSEGELEV...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>GGACT</td>\n",
       "      <td>A0A086WQ80_9VIBR/5-113</td>\n",
       "      <td>PF06094.12</td>\n",
       "      <td>LFVY...GTLRQG..ESNH.N.F.L.AD.....S...Q...........</td>\n",
       "      <td>LFVYGTLRQGESNHNFLADSQCLGHFETPPHYALYDLGTYPAVIEG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>His_kinase</td>\n",
       "      <td>Q47E94_DECAR/372-450</td>\n",
       "      <td>PF06580.13</td>\n",
       "      <td>SE.I..KLLHAQVNPHFLFNALNTL......S....AV...I.......</td>\n",
       "      <td>SEIKLLHAQVNPHFLFNALNTLSAVIRRDPEKACHLVLNLSTFFRK...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                        ...                                                                   sequence\n",
       "0      0                        ...                          PHPESRIRLSTRRDAHGMPIPRIESRLGPDAFARLRFMARTCRAIL...\n",
       "1      3                        ...                          MLRMMMNSKIHRATVTEADLNYVGSITIDEDILDAVGMLPNEKVHI...\n",
       "2      4                        ...                          TACPKQCTARGLGLKAAPVTQPTRFVVILNDCHGQPLGRSEGELEV...\n",
       "3      6                        ...                          LFVYGTLRQGESNHNFLADSQCLGHFETPPHYALYDLGTYPAVIEG...\n",
       "4      8                        ...                          SEIKLLHAQVNPHFLFNALNTLSAVIRRDPEKACHLVLNLSTFFRK...\n",
       "\n",
       "[5 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%timeit -n 100 df.col1.str.len().max()\\n100 loops, best of 3: 11.7 ms per loop\\n\\n%timeit -n 100 df.col1.map(lambda x: len(x)).max()\\n100 loops, best of 3: 16.4 ms per loop\\n\\n%timeit -n 100 df.col1.map(len).max()\\n100 loops, best of 3: 10.1 ms per loop\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "%timeit -n 100 df.col1.str.len().max()\n",
    "100 loops, best of 3: 11.7 ms per loop\n",
    "\n",
    "%timeit -n 100 df.col1.map(lambda x: len(x)).max()\n",
    "100 loops, best of 3: 16.4 ms per loop\n",
    "\n",
    "%timeit -n 100 df.col1.map(len).max()\n",
    "100 loops, best of 3: 10.1 ms per loop\n",
    "'''\n",
    "#%time df_train.sequence.map(len).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>58,223.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>148.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>113.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>51.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20%</th>\n",
       "      <td>67.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30%</th>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40%</th>\n",
       "      <td>95.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>113.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60%</th>\n",
       "      <td>135.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70%</th>\n",
       "      <td>166.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>215.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>298.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1,241.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  sequence\n",
       "count            58,223.00\n",
       "mean                148.71\n",
       "std                 113.84\n",
       "min                   6.00\n",
       "10%                  51.00\n",
       "20%                  67.00\n",
       "30%                  80.00\n",
       "40%                  95.00\n",
       "50%                 113.00\n",
       "60%                 135.00\n",
       "70%                 166.00\n",
       "80%                 215.00\n",
       "90%                 298.00\n",
       "max               1,241.00"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Train Sequence length percentiles\n",
    "pd.DataFrame(df_train.sequence.map(len)).describe(include = 'all', percentiles = [.1, .2, .3, .4, .5, .6, .7, .8, .9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7,341.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>150.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>114.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>52.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20%</th>\n",
       "      <td>67.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30%</th>\n",
       "      <td>81.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40%</th>\n",
       "      <td>97.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>115.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60%</th>\n",
       "      <td>135.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70%</th>\n",
       "      <td>169.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>217.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>304.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1,110.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  sequence\n",
       "count             7,341.00\n",
       "mean                150.38\n",
       "std                 114.87\n",
       "min                  10.00\n",
       "10%                  52.00\n",
       "20%                  67.00\n",
       "30%                  81.00\n",
       "40%                  97.00\n",
       "50%                 115.00\n",
       "60%                 135.00\n",
       "70%                 169.00\n",
       "80%                 217.00\n",
       "90%                 304.00\n",
       "max               1,110.00"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Dev Sequence length percentiles\n",
    "pd.DataFrame(df_dev.sequence.map(len)).describe(include = 'all', percentiles = [.1, .2, .3, .4, .5, .6, .7, .8, .9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7,352.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>149.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>114.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>10.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10%</th>\n",
       "      <td>51.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20%</th>\n",
       "      <td>67.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30%</th>\n",
       "      <td>80.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40%</th>\n",
       "      <td>96.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>115.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60%</th>\n",
       "      <td>138.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70%</th>\n",
       "      <td>169.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80%</th>\n",
       "      <td>215.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90%</th>\n",
       "      <td>299.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1,128.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  sequence\n",
       "count             7,352.00\n",
       "mean                149.89\n",
       "std                 114.14\n",
       "min                  10.00\n",
       "10%                  51.00\n",
       "20%                  67.00\n",
       "30%                  80.00\n",
       "40%                  96.00\n",
       "50%                 115.00\n",
       "60%                 138.00\n",
       "70%                 169.00\n",
       "80%                 215.00\n",
       "90%                 299.00\n",
       "max               1,128.00"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Test Sequence length percentiles\n",
    "pd.DataFrame(df_test.sequence.map(len)).describe(include = 'all', percentiles = [.1, .2, .3, .4, .5, .6, .7, .8, .9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nword = 'CatBatSatFatOr'\\ns_= ''\\nfor i in range(0, len(word), 1):\\n    s_ = s_ + ' ' + word[i]\\ns_\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "word = 'CatBatSatFatOr'\n",
    "s_= ''\n",
    "for i in range(0, len(word), 1):\n",
    "    s_ = s_ + ' ' + word[i]\n",
    "s_\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "06be46af056ea4e70ef958df08700b4b6397c69f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n## Selecting first 5k records for processing as a sample\\nnum_of_points=5000\\ndata = final_text_processed[0:num_of_points]\\n\\nprint(\"Min and max time values for sample data :\")\\nprint(\"Time min:\", data[\\'Time\\'].min())\\nprint(\"Time max:\", data[\\'Time\\'].max())\\n\\nX = data[\\'CleanedText\\']\\nY = np.array([1 if x==\\'positive\\' else 0 for x in data[\\'Score\\']])\\nXYTime=data[\\'Time\\']\\nprint(\"X Shape : \",X.shape, \" X Ndim: \",X.ndim)\\nprint(\"Y Shape : \",Y.shape, \" Y Ndim: \",Y.ndim)\\n#print(X); print(Y)\\nfrom scipy import stats\\nstats.describe(Y)\\n\\n## Splitting dataset into train and test with 70:30 ratio**\\n# Train to test ratio is 70:30\\nboundry=int(num_of_points*0.7)\\nprint(\"Boundry: \", boundry)\\n# split the data set into train and test based in time and not random splitting\\nx_train = X[:boundry]; x_test = X[boundry:]\\nY_train = Y[:boundry]; Y_test = Y[boundry:]\\nXYTime_train = XYTime[:boundry]; XYTime_test = XYTime[boundry:]\\n\\n#x_train, x_test, y_train, y_test = cross_validation.train_test_split(X, Y, test_size=0.3, random_state=0)\\nprint(\"x train Shape : \",x_train.shape, \" x Ndim: \",x_train.ndim); print(\"y train Shape : \",Y_train.shape, \" y Ndim: \",Y_train.ndim)\\nprint(\"x test Shape : \",x_test.shape, \" x Ndim: \",x_test.ndim); print(\"y test Shape : \",Y_test.shape, \" y Ndim: \",Y_test.ndim)\\n\\nprint(\"\\nMin and max time values for time for both train and test :\")\\nprint(\"Train Time min:\", XYTime_train.min())\\nprint(\"Train Time max:\", XYTime_train.max())\\nprint(\"Test Time min:\", XYTime_test.min())\\nprint(\"Test Time max:\", XYTime_test.max())\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "## Selecting first 5k records for processing as a sample\n",
    "num_of_points=5000\n",
    "data = final_text_processed[0:num_of_points]\n",
    "\n",
    "print(\"Min and max time values for sample data :\")\n",
    "print(\"Time min:\", data['Time'].min())\n",
    "print(\"Time max:\", data['Time'].max())\n",
    "\n",
    "X = data['CleanedText']\n",
    "Y = np.array([1 if x=='positive' else 0 for x in data['Score']])\n",
    "XYTime=data['Time']\n",
    "print(\"X Shape : \",X.shape, \" X Ndim: \",X.ndim)\n",
    "print(\"Y Shape : \",Y.shape, \" Y Ndim: \",Y.ndim)\n",
    "#print(X); print(Y)\n",
    "from scipy import stats\n",
    "stats.describe(Y)\n",
    "\n",
    "## Splitting dataset into train and test with 70:30 ratio**\n",
    "# Train to test ratio is 70:30\n",
    "boundry=int(num_of_points*0.7)\n",
    "print(\"Boundry: \", boundry)\n",
    "# split the data set into train and test based in time and not random splitting\n",
    "x_train = X[:boundry]; x_test = X[boundry:]\n",
    "Y_train = Y[:boundry]; Y_test = Y[boundry:]\n",
    "XYTime_train = XYTime[:boundry]; XYTime_test = XYTime[boundry:]\n",
    "\n",
    "#x_train, x_test, y_train, y_test = cross_validation.train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "print(\"x train Shape : \",x_train.shape, \" x Ndim: \",x_train.ndim); print(\"y train Shape : \",Y_train.shape, \" y Ndim: \",Y_train.ndim)\n",
    "print(\"x test Shape : \",x_test.shape, \" x Ndim: \",x_test.ndim); print(\"y test Shape : \",Y_test.shape, \" y Ndim: \",Y_test.ndim)\n",
    "\n",
    "print(\"\\nMin and max time values for time for both train and test :\")\n",
    "print(\"Train Time min:\", XYTime_train.min())\n",
    "print(\"Train Time max:\", XYTime_train.max())\n",
    "print(\"Test Time min:\", XYTime_test.min())\n",
    "print(\"Test Time max:\", XYTime_test.max())\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "772b9a6b310f658bdc2e9fd1afd2e0591927cddd"
   },
   "source": [
    "\n",
    "## **Preprocessing **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9168e2dee8fd28eda945afc6cfbb48c9eadce99f"
   },
   "source": [
    "**Lets define functions here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "df024b9633bd5b1935734ad3cff519e096206d80"
   },
   "outputs": [],
   "source": [
    "def seq2_space_seperated_chars(word):\n",
    "    '''\n",
    "    Wequence to space seperated characters. Example: 'ABCDEFG' to ' A B C D E F G'\n",
    "    '''\n",
    "    s_= ''\n",
    "    for i in range(0, len(word), 1):\n",
    "        s_ = s_ + ' ' + word[i]\n",
    "    return s_\n",
    "\n",
    "#seq2_space_seperated_chars(df_train.sequence[2])\n",
    "\n",
    "def top_freq_features(df, n):\n",
    "    return df[:n]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "113b591594f663e0c352f87156bc6342594ae3ce"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "# https://gist.github.com/greydanus/f6eee59eaf1d90fcb3b534a25362cea4\n",
    "# https://stackoverflow.com/a/14434334\n",
    "# this function is used to update the plots for each epoch and error\n",
    "def plt_dynamic(fig, x, vy, ty, ax, colors=['b']):\n",
    "    ax.plot(x, vy, 'b', label=\"Validation Loss\")\n",
    "    ax.plot(x, ty, 'r', label=\"Train Loss\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    fig.canvas.draw()\n",
    "    plt.show()\n",
    "    \n",
    "def compile_execute_model():\n",
    "    \"\"\"Compile, execute and evaluate the model. Get \"Categorical Crossentropy Loss\" vs \"epocs\" plot\"\"\"\n",
    "    print(\"Model Summary:\")\n",
    "    model.summary()\n",
    "    print(\"Model Compilation:\")\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    print(\"Model Execution:\")\n",
    "    history = model.fit(X_train, y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_cv, y_cv))\n",
    "    score = model.evaluate(X_test, y_test, verbose=0) \n",
    "    print('cv score:', score[0]) \n",
    "    print('cv accuracy:', score[1])\n",
    "    \n",
    "    model_pretty_table.add_row([model_name, round(score[0]*100,2), round(score[1]*100,2)])\n",
    "    \n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
    "\n",
    "    # list of epoch numbers\n",
    "    x = list(range(1,nb_epoch+1))\n",
    "\n",
    "    vy = history.history['val_loss']\n",
    "    ty = history.history['loss']\n",
    "    plt_dynamic(fig, x, vy, ty, ax)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert seperate genes with space in sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.63 s, sys: 0 ns, total: 1.63 s\n",
      "Wall time: 1.63 s\n",
      "CPU times: user 204 ms, sys: 0 ns, total: 204 ms\n",
      "Wall time: 200 ms\n",
      "CPU times: user 204 ms, sys: 0 ns, total: 204 ms\n",
      "Wall time: 203 ms\n",
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 452 µs\n",
      "CPU times: user 180 ms, sys: 0 ns, total: 180 ms\n",
      "Wall time: 179 ms\n",
      "CPU times: user 24 ms, sys: 0 ns, total: 24 ms\n",
      "Wall time: 23.7 ms\n",
      "CPU times: user 24 ms, sys: 0 ns, total: 24 ms\n",
      "Wall time: 24.1 ms\n"
     ]
    }
   ],
   "source": [
    "#%time x_train = df_train.sequence.apply((lambda x: seq2_space_seperated_chars(x)))\n",
    "#%time x_cv    = df_dev.sequence.apply((lambda x: seq2_space_seperated_chars(x)))\n",
    "#%time x_test  = df_test.sequence.apply((lambda x: seq2_space_seperated_chars(x)))\n",
    "\n",
    "%time x_train = df_train.sequence.apply(seq2_space_seperated_chars)\n",
    "%time x_cv    = df_dev.sequence.apply(seq2_space_seperated_chars)\n",
    "%time x_test  = df_test.sequence.apply(seq2_space_seperated_chars)\n",
    "\n",
    "values   = np.arange(0,len(df_train.family_accession.unique()),1)\n",
    "keys = df_train.family_accession.unique()\n",
    "%time dict_class = dict(zip(keys, values))\n",
    "\n",
    "%time y_train = df_train.family_accession.apply(lambda x: dict_class[x])\n",
    "%time y_cv    = df_dev.family_accession.apply(lambda x: dict_class[x])\n",
    "%time y_test  = df_test.family_accession.apply(lambda x: dict_class[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     P H P E S R I R L S T R R D A H G M P I P R I...\n",
       "1     M L R M M M N S K I H R A T V T E A D L N Y V...\n",
       "2     T A C P K Q C T A R G L G L K A A P V T Q P T...\n",
       "3     L F V Y G T L R Q G E S N H N F L A D S Q C L...\n",
       "4     S E I K L L H A Q V N P H F L F N A L N T L S...\n",
       "Name: sequence, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# here we are having a class number for each image\\nprint(\"Number of unique classes :\", number_of_unique_classes)\\nprint(\"Before converting the output into a vector : \",y_train[0])\\n# lets convert this into a 10 dimensional vector\\n# ex: consider an image is 5 convert it into 5 => [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\\n# this conversion needed for MLPs \\n\\nfrom keras.utils import np_utils \\n#Y_train = np_utils.to_categorical(y_train, number_of_unique_classes) \\nY_cv    = np_utils.to_categorical(y_cv, number_of_unique_classes) \\nY_test  = np_utils.to_categorical(y_test, number_of_unique_classes)\\n\\nprint(\"After converting the output into a vector : \",Y_train[0])\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# here we are having a class number for each image\n",
    "print(\"Number of unique classes :\", number_of_unique_classes)\n",
    "print(\"Before converting the output into a vector : \",y_train[0])\n",
    "# lets convert this into a 10 dimensional vector\n",
    "# ex: consider an image is 5 convert it into 5 => [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
    "# this conversion needed for MLPs \n",
    "\n",
    "from keras.utils import np_utils \n",
    "#Y_train = np_utils.to_categorical(y_train, number_of_unique_classes) \n",
    "Y_cv    = np_utils.to_categorical(y_cv, number_of_unique_classes) \n",
    "Y_test  = np_utils.to_categorical(y_test, number_of_unique_classes)\n",
    "\n",
    "print(\"After converting the output into a vector : \",Y_train[0])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom keras.utils import np_utils\\ndef get_categorical(y_train, number_of_unique_classes):\\n    Y_train = []\\n    for class_ in y_train:\\n        class__ = np_utils.to_categorical(class_, number_of_unique_classes) \\n        Y_train.append(class__)\\n    Y_train = np.array(Y_train)\\n    return Y_train\\n\\n%time Y_train = get_categorical(y_train, number_of_unique_classes)\\n%time Y_cv    = get_categorical(y_cv, number_of_unique_classes)\\n%time Y_test  = get_categorical(y_test, number_of_unique_classes)\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from keras.utils import np_utils\n",
    "def get_categorical(y_train, number_of_unique_classes):\n",
    "    Y_train = []\n",
    "    for class_ in y_train:\n",
    "        class__ = np_utils.to_categorical(class_, number_of_unique_classes) \n",
    "        Y_train.append(class__)\n",
    "    Y_train = np.array(Y_train)\n",
    "    return Y_train\n",
    "\n",
    "%time Y_train = get_categorical(y_train, number_of_unique_classes)\n",
    "%time Y_cv    = get_categorical(y_cv, number_of_unique_classes)\n",
    "%time Y_test  = get_categorical(y_test, number_of_unique_classes)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/52476191/what-does-initial-epoch-in-keras-mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58223,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\na = []\\na.append([1,2,3])\\na.append([1,2,3])\\nnp.array(a)\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "a = []\n",
    "a.append([1,2,3])\n",
    "a.append([1,2,3])\n",
    "np.array(a)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_class = pd.DataFrame(y_train.unique()); df_class.columns = ['class']\n",
    "#def get_class_index(class_):\n",
    "#    return np.where(df_class['class']=='PF05750.11')[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8ba9b52b17d2a383d68fd6b27a421f3f9bf55117"
   },
   "source": [
    "**Lets use BoW for word counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "e8c72de9ab0e0a20752ce2a40985dbc67a777214"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.37 s, sys: 8 ms, total: 4.38 s\n",
      "Wall time: 4.39 s\n",
      "CPU times: user 4.53 s, sys: 0 ns, total: 4.53 s\n",
      "Wall time: 4.53 s\n",
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 2.48 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(22,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BoW\n",
    "feature_transform = 'BoW'\n",
    "\n",
    "#bow_scalar = CountVectorizer() #in scikit-learn\n",
    "#ValueError: empty vocabulary; perhaps the documents only contain stop words\n",
    "# https://stackoverflow.com/questions/43601358/empty-vocabulary-for-single-letter-by-countvectorizer\n",
    "#The default token_pattern regexp in CountVectorizer selects words which have atleast 2 chars\n",
    "#From the source code of CountVectorizer it is r\"(?u)\\b\\w\\w+\\b\n",
    "#Change it to r\"(?u)\\b\\w+\\b to include 1 letter words.\n",
    "\n",
    "bow_scalar = CountVectorizer(token_pattern = r\"(?u)\\b\\w+\\b\")\n",
    "%time bow_scalar.fit(x_train.values)\n",
    "\n",
    "%time final_counts = bow_scalar.transform(x_train.values).toarray()\n",
    "%time final_counts = final_counts.sum(axis=0)\n",
    "final_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "30f57f58e2990ca66729f5cd6b3bc777d6767742"
   },
   "source": [
    "**Creating tabular format as feature against frequency in descending order**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "7130daa213c2df242c73373e66d8335b872662d7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l</td>\n",
       "      <td>871732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>768427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g</td>\n",
       "      <td>642139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v</td>\n",
       "      <td>634987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>546656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i</td>\n",
       "      <td>545484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>s</td>\n",
       "      <td>516287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>r</td>\n",
       "      <td>480616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>d</td>\n",
       "      <td>476275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>t</td>\n",
       "      <td>464050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>k</td>\n",
       "      <td>456280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>p</td>\n",
       "      <td>372666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>f</td>\n",
       "      <td>361920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>n</td>\n",
       "      <td>327154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>q</td>\n",
       "      <td>303387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>y</td>\n",
       "      <td>278917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>m</td>\n",
       "      <td>195535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>h</td>\n",
       "      <td>187818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>c</td>\n",
       "      <td>115968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>w</td>\n",
       "      <td>112038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>x</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature  frequency\n",
       "0        l     871732\n",
       "1        a     768427\n",
       "2        g     642139\n",
       "3        v     634987\n",
       "4        e     546656\n",
       "5        i     545484\n",
       "6        s     516287\n",
       "7        r     480616\n",
       "8        d     476275\n",
       "9        t     464050\n",
       "10       k     456280\n",
       "11       p     372666\n",
       "12       f     361920\n",
       "13       n     327154\n",
       "14       q     303387\n",
       "15       y     278917\n",
       "16       m     195535\n",
       "17       h     187818\n",
       "18       c     115968\n",
       "19       w     112038\n",
       "20       x         95\n",
       "21       b          1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({ 'feature': bow_scalar.get_feature_names(),'frequency': list(final_counts) })\n",
    "df.sort_values('frequency', ascending = False, inplace = True)\n",
    "df.reset_index(drop=True, inplace = True)\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>l</td>\n",
       "      <td>871732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>768427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g</td>\n",
       "      <td>642139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v</td>\n",
       "      <td>634987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e</td>\n",
       "      <td>546656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>i</td>\n",
       "      <td>545484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>s</td>\n",
       "      <td>516287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>r</td>\n",
       "      <td>480616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>d</td>\n",
       "      <td>476275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>t</td>\n",
       "      <td>464050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>k</td>\n",
       "      <td>456280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>p</td>\n",
       "      <td>372666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>f</td>\n",
       "      <td>361920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>n</td>\n",
       "      <td>327154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>q</td>\n",
       "      <td>303387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>y</td>\n",
       "      <td>278917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>m</td>\n",
       "      <td>195535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>h</td>\n",
       "      <td>187818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>c</td>\n",
       "      <td>115968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>w</td>\n",
       "      <td>112038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>x</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>b</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature  frequency\n",
       "0        l     871732\n",
       "1        a     768427\n",
       "2        g     642139\n",
       "3        v     634987\n",
       "4        e     546656\n",
       "5        i     545484\n",
       "6        s     516287\n",
       "7        r     480616\n",
       "8        d     476275\n",
       "9        t     464050\n",
       "10       k     456280\n",
       "11       p     372666\n",
       "12       f     361920\n",
       "13       n     327154\n",
       "14       q     303387\n",
       "15       y     278917\n",
       "16       m     195535\n",
       "17       h     187818\n",
       "18       c     115968\n",
       "19       w     112038\n",
       "20       x         95\n",
       "21       b          1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(word):\n",
    "    word = word.lower()\n",
    "    #print(\"word: \", word)\n",
    "    temp = df['feature'] == word\n",
    "    #print(\"temp type: \", type(temp))\n",
    "    temp_sum = np.array(temp).sum()\n",
    "    #print(\"temp: \", temp_sum)\n",
    "    if(temp_sum ==1):\n",
    "        return df.index[df['feature'] == word].tolist()[0]\n",
    "    else:\n",
    "        #return -99\n",
    "        return top_words\n",
    "    \n",
    "#get_index('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58223,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lpad_reviews_with_index_content(x_train, max_review_length = 600):\n",
    "    X_train = numpy.zeros((x_train.shape[0], max_review_length), dtype = 'int')\n",
    "    \n",
    "    #print(\"X_train: \", X_train.dtype)\n",
    "    #print(\"np.arange(0,len(x_train)): \", np.arange(0,len(x_train)))\n",
    "    #print(\"x_train: \", len(x_train))\n",
    "    i = 0\n",
    "    for zz in tqdm(np.arange(0,len(x_train))):\n",
    "        #print(\"zz: \",zz)\n",
    "        x = x_train[zz]\n",
    "        #print(\"x: \",x)\n",
    "        x_iter = map(get_index, x.split())\n",
    "        \n",
    "        l1 = list(x_iter)  \n",
    "        #print(\"x_iter: \",l1)\n",
    "        l = list(filter(lambda x: (x != -99), l1))\n",
    "        len_l1 = len(l1)\n",
    "        len_l = len(l)\n",
    "        #if(len_l1 != len_l):\n",
    "            #print('l1 with -99: ',l1)\n",
    "            #print('l without -99: ',l)\n",
    "        A = np.array(l)\n",
    "        left_pad_number = max_review_length - A.shape[0]\n",
    "        if(left_pad_number < 0):\n",
    "            #print(\"More number of words found than \", max_review_length, \", keeping first \", max_review_length, \" words\")\n",
    "            A=A[:max_review_length]\n",
    "            left_pad_number = 0\n",
    "        A = np.pad(A, (left_pad_number, 0), 'constant')  \n",
    "        X_train[i] = A\n",
    "        i = i+1\n",
    "    return X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:00<00:00, 17.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 ms, sys: 0 ns, total: 4 ms\n",
      "Wall time: 496 µs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 17.78it/s]\n"
     ]
    }
   ],
   "source": [
    "top_words = 20\n",
    "max_review_length = 50\n",
    "from tqdm import tqdm\n",
    "## Considering max review length as 400 with left padding zeros\n",
    "%time df = top_freq_features(df, top_words)\n",
    "\n",
    "X_train = lpad_reviews_with_index_content(x_train[:10], max_review_length)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[11, 17, 11,  4,  6,  7,  5,  7,  0,  6,  9,  7,  7,  8,  1, 17,\n",
       "         2, 16, 11,  5, 11,  7,  5,  4,  6,  7,  0,  2, 11,  8,  1, 12,\n",
       "         1,  7,  0,  7, 12, 16,  1,  7,  9, 18,  7,  1,  5,  0,  1,  1,\n",
       "         1,  2],\n",
       "       [16,  0,  7, 16, 16, 16, 13,  6, 10,  5, 17,  7,  1,  9,  3,  9,\n",
       "         4,  1,  8,  0, 13, 15,  3,  2,  6,  5,  9,  5,  8,  4,  8,  5,\n",
       "         0,  8,  1,  3,  2, 16,  0, 11, 13,  4, 10,  3, 17,  5,  3, 13,\n",
       "        13, 13],\n",
       "       [ 9,  1, 18, 11, 10, 14, 18,  9,  1,  7,  2,  0,  2,  0, 10,  1,\n",
       "         1, 11,  3,  9, 14, 11,  9,  7, 12,  3,  3,  5,  0, 13,  8, 18,\n",
       "        17,  2, 14, 11,  0,  2,  7,  6,  4,  2,  4,  0,  4,  3,  8,  5,\n",
       "         3,  9],\n",
       "       [ 0, 12,  3, 15,  2,  9,  0,  7, 14,  2,  4,  6, 13, 17, 13, 12,\n",
       "         0,  1,  8,  6, 14, 18,  0,  2, 17, 12,  4,  9, 11, 11, 17, 15,\n",
       "         1,  0, 15,  8,  0,  2,  9, 15, 11,  1,  3,  5,  4,  2, 17,  8,\n",
       "         9,  5],\n",
       "       [ 6,  4,  5, 10,  0,  0, 17,  1, 14,  3, 13, 11, 17, 12,  0, 12,\n",
       "        13,  1,  0, 13,  9,  0,  6,  1,  3,  5,  7,  7,  8, 11,  4, 10,\n",
       "         1, 18, 17,  0,  3,  0, 13,  0,  6,  9, 12, 12,  7, 10, 13,  0,\n",
       "        10,  7],\n",
       "       [ 0,  7,  5,  1,  9,  7, 10,  6, 11,  0,  1,  0, 19, 14,  1,  4,\n",
       "        15,  3,  1,  6,  7,  0,  7,  1,  1, 17, 11,  8,  0,  7,  3,  4,\n",
       "         0,  3,  2, 16,  9,  9,  7,  2,  8, 10,  0,  0,  8,  1, 11,  0,\n",
       "         1, 10],\n",
       "       [12,  1,  1, 12,  2, 18,  6,  1, 12,  1,  5,  9,  1, 18,  0,  3,\n",
       "         3,  5,  6,  6,  1, 15, 16,  3,  3, 10,  4,  5,  2,  8,  4,  3,\n",
       "         0,  8,  4,  5, 14, 16, 12,  7,  6,  4,  5,  8,  6,  1, 19,  6,\n",
       "         4,  5],\n",
       "       [10,  5, 10,  9, 13, 14,  3,  0,  4,  8,  2, 14,  0, 14,  9,  5,\n",
       "         4,  1, 12, 15,  7,  2,  4,  7,  3,  8, 10, 13,  2,  8,  5, 12,\n",
       "         3,  6, 12,  8,  4, 12,  8, 10,  3, 10,  5,  6, 10,  9,  9,  5,\n",
       "        10,  5],\n",
       "       [ 0, 15, 17,  1,  6,  5, 11, 16, 16,  3, 10, 15,  0,  2, 13,  0,\n",
       "        10,  3,  5,  0,  5, 10,  1,  4, 10, 17, 18,  1,  1, 10, 13,  0,\n",
       "        13, 11,  4,  4, 16,  5, 10, 12,  7,  0,  5,  4,  8, 16,  7,  6,\n",
       "         0,  8],\n",
       "       [10,  9,  7,  0,  6, 15,  1,  1,  2,  6,  9,  0,  2, 14,  8,  5,\n",
       "        14,  9, 16,  5,  1,  4,  7, 14,  4, 19,  2,  3, 11,  3,  8, 10,\n",
       "         5,  1,  0,  0,  1,  2,  3,  3,  8,  6,  3,  6,  2, 17,  0, 14,\n",
       "         0, 11]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique_indexes:  21\n"
     ]
    }
   ],
   "source": [
    "unique_indexes = top_words + 1\n",
    "print(\"unique_indexes: \", unique_indexes)\n",
    "#Y_train_ = get_categorical(y_train[index : index + unique_indexes], unique_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "def get_categorical(y_train, number_of_unique_classes):\n",
    "    Y_train = []\n",
    "    for class_ in y_train:\n",
    "        class__ = np_utils.to_categorical(class_, number_of_unique_classes) \n",
    "        Y_train.append(class__)\n",
    "    Y_train = np.array(Y_train)\n",
    "    return Y_train\n",
    "\n",
    "#l = get_categorical([0], unique_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ohe_index_seq(array_of_seq):\n",
    "    from tqdm import tqdm\n",
    "    array_ohe = []\n",
    "    #print(\"array_of_seq: \", len(array_of_seq))\n",
    "    from tqdm import tqdm\n",
    "    for i in tqdm(np.arange(0,len(array_of_seq))):\n",
    "        ohe = []\n",
    "        seq = array_of_seq[i]\n",
    "        seq = seq.ravel().tolist()\n",
    "        #print(\"seq: \",seq)\n",
    "        for index in seq :  \n",
    "            #print(\"index: \", index)\n",
    "            ohe_temp = get_categorical([index], unique_indexes)\n",
    "            ohe_temp = ohe_temp.ravel().tolist()\n",
    "            #print(\"ohe_temp: \", ohe_temp)\n",
    "            ohe.append(ohe_temp)\n",
    "        #print(ohe)  \n",
    "        #return np.array(ohe)\n",
    "        array_ohe.append(ohe)\n",
    "    return np.array(array_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 950.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing function for one rec:  [[11 17 11  4  6  7  5  7  0  6  9  7  7  8  1 17  2 16 11  5 11  7  5  4\n",
      "   6  7  0  2 11  8  1 12  1  7  0  7 12 16  1  7  9 18  7  1  5  0  1  1\n",
      "   1  2]\n",
      " [16  0  7 16 16 16 13  6 10  5 17  7  1  9  3  9  4  1  8  0 13 15  3  2\n",
      "   6  5  9  5  8  4  8  5  0  8  1  3  2 16  0 11 13  4 10  3 17  5  3 13\n",
      "  13 13]\n",
      " [ 9  1 18 11 10 14 18  9  1  7  2  0  2  0 10  1  1 11  3  9 14 11  9  7\n",
      "  12  3  3  5  0 13  8 18 17  2 14 11  0  2  7  6  4  2  4  0  4  3  8  5\n",
      "   3  9]\n",
      " [ 0 12  3 15  2  9  0  7 14  2  4  6 13 17 13 12  0  1  8  6 14 18  0  2\n",
      "  17 12  4  9 11 11 17 15  1  0 15  8  0  2  9 15 11  1  3  5  4  2 17  8\n",
      "   9  5]\n",
      " [ 6  4  5 10  0  0 17  1 14  3 13 11 17 12  0 12 13  1  0 13  9  0  6  1\n",
      "   3  5  7  7  8 11  4 10  1 18 17  0  3  0 13  0  6  9 12 12  7 10 13  0\n",
      "  10  7]\n",
      " [ 0  7  5  1  9  7 10  6 11  0  1  0 19 14  1  4 15  3  1  6  7  0  7  1\n",
      "   1 17 11  8  0  7  3  4  0  3  2 16  9  9  7  2  8 10  0  0  8  1 11  0\n",
      "   1 10]\n",
      " [12  1  1 12  2 18  6  1 12  1  5  9  1 18  0  3  3  5  6  6  1 15 16  3\n",
      "   3 10  4  5  2  8  4  3  0  8  4  5 14 16 12  7  6  4  5  8  6  1 19  6\n",
      "   4  5]\n",
      " [10  5 10  9 13 14  3  0  4  8  2 14  0 14  9  5  4  1 12 15  7  2  4  7\n",
      "   3  8 10 13  2  8  5 12  3  6 12  8  4 12  8 10  3 10  5  6 10  9  9  5\n",
      "  10  5]\n",
      " [ 0 15 17  1  6  5 11 16 16  3 10 15  0  2 13  0 10  3  5  0  5 10  1  4\n",
      "  10 17 18  1  1 10 13  0 13 11  4  4 16  5 10 12  7  0  5  4  8 16  7  6\n",
      "   0  8]\n",
      " [10  9  7  0  6 15  1  1  2  6  9  0  2 14  8  5 14  9 16  5  1  4  7 14\n",
      "   4 19  2  3 11  3  8 10  5  1  0  0  1  2  3  3  8  6  3  6  2 17  0 14\n",
      "   0 11]]\n",
      "X_train.shape:  (10, 50)\n",
      "X_train_ohe.shape:  (10, 50, 21)\n",
      "X_train_ohe: \n",
      " [[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"testing function for one rec: \", X_train[:])\n",
    "X_train_ohe = ohe_index_seq(X_train[:])\n",
    "\n",
    "print(\"X_train.shape: \", X_train.shape)\n",
    "print(\"X_train_ohe.shape: \", X_train_ohe.shape)\n",
    "print(\"X_train_ohe: \\n\",X_train_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#garbage collecting\n",
    "import gc\n",
    "#del [[df_fail_tasks_, df_success_tasks_]]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#garbage collecting\n",
    "import gc\n",
    "del [[X_train_ohe, X_train]]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "8a28c607026743733b44de08eaeea84bc28fa277"
   },
   "source": [
    "* **Get the top 20 highest frequency words**\n",
    "* **Considering max review length as 400 with left padding zeros**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "_uuid": "1cdac3d68b73103df8f35dc2593b9042b0a18237",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 495 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n## Considering max review length as 400 with left padding zeros\\nimport os\\nif not os.path.isfile(\\'../input/X_train.csv\\'):\\n    print(\"calculating X_train ...\")\\n    %time X_train = lpad_reviews_with_index_content(x_train[:], max_review_length)    \\n    %time pd.DataFrame(X_train).to_csv(\"X_train.csv\", index=False, mode = \\'w\\', header = True)\\n\\n\\nif not os.path.isfile(\\'../input/X_cv.csv\\'):\\n    print(\"calculating X_cv ...\")\\n    %time X_cv = lpad_reviews_with_index_content(x_cv[:], max_review_length)\\n    %time pd.DataFrame(X_cv).to_csv(\"X_cv.csv\", index=False, mode = \\'w\\', header = True)\\n\\n\\nif not os.path.isfile(\\'../input/X_test.csv\\'):\\n    print(\"calculating X_test ...\")\\n    %time X_test  = lpad_reviews_with_index_content(x_test[:], max_review_length)\\n    %time pd.DataFrame(X_test).to_csv(\"X_test.csv\", index=False, mode = \\'w\\', header = True)\\n\\n       \\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top_words = 20\n",
    "#max_review_length = 400\n",
    "\n",
    "top_words = 10\n",
    "max_review_length = 50\n",
    "\n",
    "## Considering max review length as 400 with left padding zeros\n",
    "%time df = top_freq_features(df, top_words)\n",
    "\n",
    "'''\n",
    "## Considering max review length as 400 with left padding zeros\n",
    "import os\n",
    "if not os.path.isfile('../input/X_train.csv'):\n",
    "    print(\"calculating X_train ...\")\n",
    "    %time X_train = lpad_reviews_with_index_content(x_train[:], max_review_length)    \n",
    "    %time pd.DataFrame(X_train).to_csv(\"X_train.csv\", index=False, mode = 'w', header = True)\n",
    "\n",
    "\n",
    "if not os.path.isfile('../input/X_cv.csv'):\n",
    "    print(\"calculating X_cv ...\")\n",
    "    %time X_cv = lpad_reviews_with_index_content(x_cv[:], max_review_length)\n",
    "    %time pd.DataFrame(X_cv).to_csv(\"X_cv.csv\", index=False, mode = 'w', header = True)\n",
    "\n",
    "\n",
    "if not os.path.isfile('../input/X_test.csv'):\n",
    "    print(\"calculating X_test ...\")\n",
    "    %time X_test  = lpad_reviews_with_index_content(x_test[:], max_review_length)\n",
    "    %time pd.DataFrame(X_test).to_csv(\"X_test.csv\", index=False, mode = 'w', header = True)\n",
    "\n",
    "       \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"loading X_train from file...\")\n",
    "#X_train = pd.read_csv(\"X_train.csv\").values\n",
    "#print(\"X_train: \", X_train.shape); print(X_train[0:5])\n",
    "\n",
    "#print(\"loading X_cv from file...\")\n",
    "#X_cv    = pd.read_csv(\"X_cv.csv\").values \n",
    "#print(\"X_cv: \", X_cv.shape);       print(X_cv[0:5])\n",
    "\n",
    "#print(\"loading X_test from file...\")\n",
    "#X_test  = pd.read_csv(\"X_test.csv\").values \n",
    "#print(\"X_test: \", X_test.shape);   print(X_test[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### garbage colleting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "#del [[x_train, x_cv, x_test, X_train, X_cv, X_test]]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "#del [[x_train, x_cv, x_test, X_train, X_cv, X_test]]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1248.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 1050)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train        = pd.read_csv(\"../input/X_train.csv\").values\n",
    "def ohe_index_seq_(array_of_seq):\n",
    "    from tqdm import tqdm\n",
    "    array_ohe = []\n",
    "    #print(\"array_of_seq: \", len(array_of_seq))\n",
    "    from tqdm import tqdm\n",
    "    for i in tqdm(np.arange(0,len(array_of_seq))):\n",
    "        ohe = []\n",
    "        seq = array_of_seq[i]\n",
    "        seq = seq.ravel().tolist()\n",
    "        #print(\"seq: \",seq)\n",
    "        for index in seq :  \n",
    "            #print(\"index: \", index)\n",
    "            ohe_temp = get_categorical([index], unique_indexes)\n",
    "            ohe_temp = ohe_temp.ravel().tolist()\n",
    "            #print(\"ohe_temp: \", ohe_temp)\n",
    "            ohe.append(ohe_temp)\n",
    "        #print(ohe)  \n",
    "        ohe = np.array(ohe).ravel().tolist()\n",
    "        #return np.array(ohe)\n",
    "        array_ohe.append(ohe)\n",
    "    return np.array(array_ohe)\n",
    "\n",
    "X_train_ = ohe_index_seq_(X_train[:10])  \n",
    "X_train_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one hot encoding cv and test datasets below. x_train will be one hot encoded at runtime while training LSTM since x_train is very big and consumes too much memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 58223/58223 [00:48<00:00, 1205.19it/s]\n",
      "  2%|▏         | 158/7341 [00:00<00:04, 1567.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 46.7 s, sys: 8.48 s, total: 55.2 s\n",
      "Wall time: 53 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7341/7341 [00:05<00:00, 1424.69it/s]\n",
      "  2%|▏         | 155/7352 [00:00<00:04, 1549.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.34 s, sys: 592 ms, total: 5.93 s\n",
      "Wall time: 5.57 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7352/7352 [00:05<00:00, 1440.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.34 s, sys: 528 ms, total: 5.87 s\n",
      "Wall time: 5.55 s\n",
      "X_train:  (58223, 1050)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "X_cv:  (7341, 1050)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "X_test:  (7352, 1050)\n",
      "[[0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X_train        = pd.read_csv(\"../input/X_train.csv\").values\n",
    "%time X_train  = ohe_index_seq_(X_train[:])  \n",
    "X_cv           = pd.read_csv(\"../input/X_cv.csv\").values \n",
    "%time X_cv     = ohe_index_seq_(X_cv[:]) \n",
    "X_test         = pd.read_csv(\"../input/X_test.csv\").values \n",
    "%time X_test   = ohe_index_seq_(X_test[:]) \n",
    "\n",
    "print(\"X_train: \", X_train.shape); print(X_train[0:5])\n",
    "print(\"X_cv: \", X_cv.shape);       print(X_cv[0:5])\n",
    "print(\"X_test: \", X_test.shape);   print(X_test[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58223, 1050)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif not os.path.isfile(\\'X_cv_ohe.csv\\'):\\n    \\n    print(\"loading X_cv from file...\")\\n    X_cv    = pd.read_csv(\"X_cv.csv\").values \\n    print(\"X_cv: \", X_cv.shape);       print(X_cv[0:5])\\n    \\n    print(\"calculating X_cv ohe...\")\\n    %time X_cv_ohe = ohe_index_seq(X_cv[:]) \\n    %time pd.DataFrame(X_cv_ohe).to_csv(\"X_cv_ohe.csv\", index=False, mode = \\'w\\', header = True)\\n\\n\\nif not os.path.isfile(\\'X_test_ohe.csv\\'):\\n    \\n    print(\"loading X_test from file...\")\\n    X_test  = pd.read_csv(\"X_test.csv\").values \\n    print(\"X_test: \", X_test.shape);   print(X_test[0:5])\\n    \\n    print(\"calculating X_test ohe...\")\\n    %time X_test_ohe  = ohe_index_seq(X_test[:]) \\n    %time pd.DataFrame(X_test_ohe).to_csv(\"X_test_ohe.csv\", index=False, mode = \\'w\\', header = True)\\n     \\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "'''\n",
    "if not os.path.isfile('X_train_ohe.csv'):\n",
    "    print(\"loading X_train from file...\")\n",
    "    X_train    = pd.read_csv(\"X_train.csv\").values \n",
    "    print(\"X_train: \", X_train.shape);       print(X_train[0:5])\n",
    "    \n",
    "    print(\"calculating X_train ...\")\n",
    "    %time X_train_ohe = ohe_index_seq(X_train[:])   \n",
    "    %time pd.DataFrame(X_train_ohe).to_csv(\"X_train_ohe.csv\", index=False, mode = 'w', header = True)\n",
    "\n",
    "     \n",
    "'''\n",
    "'''\n",
    "if not os.path.isfile('X_cv_ohe.csv'):\n",
    "    \n",
    "    print(\"loading X_cv from file...\")\n",
    "    X_cv    = pd.read_csv(\"X_cv.csv\").values \n",
    "    print(\"X_cv: \", X_cv.shape);       print(X_cv[0:5])\n",
    "    \n",
    "    print(\"calculating X_cv ohe...\")\n",
    "    %time X_cv_ohe = ohe_index_seq(X_cv[:]) \n",
    "    %time pd.DataFrame(X_cv_ohe).to_csv(\"X_cv_ohe.csv\", index=False, mode = 'w', header = True)\n",
    "\n",
    "\n",
    "if not os.path.isfile('X_test_ohe.csv'):\n",
    "    \n",
    "    print(\"loading X_test from file...\")\n",
    "    X_test  = pd.read_csv(\"X_test.csv\").values \n",
    "    print(\"X_test: \", X_test.shape);   print(X_test[0:5])\n",
    "    \n",
    "    print(\"calculating X_test ohe...\")\n",
    "    %time X_test_ohe  = ohe_index_seq(X_test[:]) \n",
    "    %time pd.DataFrame(X_test_ohe).to_csv(\"X_test_ohe.csv\", index=False, mode = 'w', header = True)\n",
    "     \n",
    "'''    \n",
    "#    \n",
    "\n",
    "#print(\"loading X_train from file...\")\n",
    "#X_train = pd.read_csv(\"X_train_ohe.csv\").values  \n",
    "#print(\"loading X_cv ohe from file...\")\n",
    "#X_cv    = pd.read_csv(\"X_cv_ohe.csv\").values\n",
    "#print(\"loading X_test ohe from file...\")\n",
    "#X_test  = pd.read_csv(\"X_test_ohe.csv\").values\n",
    "\n",
    "#print(\"X_train: \", X_train.shape); print(X_train[0:5])\n",
    "#print(\"X_cv: \", X_cv.shape);       print(X_cv[0:5])\n",
    "#print(\"X_test: \", X_test.shape);   print(X_test[0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "#del [[df_fail_tasks_, df_success_tasks_]]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 112 ms, sys: 52 ms, total: 164 ms\n",
      "Wall time: 160 ms\n",
      "CPU times: user 104 ms, sys: 56 ms, total: 160 ms\n",
      "Wall time: 157 ms\n"
     ]
    }
   ],
   "source": [
    "#%time Y_train = get_categorical(y_train, number_of_unique_classes)\n",
    "#%time Y_cv    = get_categorical(y_cv[0:200], number_of_unique_classes)\n",
    "#%time Y_test  = get_categorical(y_test[0:200], number_of_unique_classes)\n",
    "\n",
    "%time Y_cv    = get_categorical(y_cv, number_of_unique_classes)\n",
    "%time Y_test  = get_categorical(y_test, number_of_unique_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "#del [[df_fail_tasks_, df_success_tasks_]]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b49aa1f0253115fc8626a806362e6f40fa863de7"
   },
   "source": [
    "## **1 Layer LSTM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "_uuid": "b24024a9710d5f224bc15118c6583a3e88b57bd8",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Summary:\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1050, 8)           80        \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 16)                1600      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2884)              49028     \n",
      "=================================================================\n",
      "Total params: 50,708\n",
      "Trainable params: 50,708\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model Compilation:\n",
      "Model Execution:\n"
     ]
    }
   ],
   "source": [
    "# create the model\n",
    "model_name = '1 Layer LSTM Model'\n",
    "#nb_epoch=10\n",
    "#batch_size=1000\n",
    "\n",
    "output_dim=number_of_unique_classes\n",
    "\n",
    "#embedding_vecor_length = 10\n",
    "#embedding_vecor_length = 2048\n",
    "#embedding_vecor_length = 32\n",
    "embedding_vecor_length = 8\n",
    "model = Sequential()\n",
    "#model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "#https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=1050))\n",
    "model.add(LSTM(16))\n",
    "#model.add(Dense(1, activation='sigmoid'))\n",
    "model.add(Dense(output_dim, activation='softmax'))\n",
    "#compile_execute_model()\n",
    "#model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#print(model.summary())\n",
    "#Refer: https://datascience.stackexchange.com/questions/10615/number-of-parameters-in-an-lstm-model\n",
    "\n",
    "\n",
    "\"\"\"Compile, execute and evaluate the model. Get \"Categorical Crossentropy Loss\" vs \"epocs\" plot\"\"\"\n",
    "print(\"Model Summary:\")\n",
    "model.summary()\n",
    "print(\"Model Compilation:\")\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "print(\"Model Execution:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58223"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toal epochs:  568.583984375\n"
     ]
    }
   ],
   "source": [
    "#batch_size=100\n",
    "#number_of_epocs_trained  = 0\n",
    "#epochs_in_each_iteration = 5\n",
    "#nb_epoch         = epochs_in_each_iteration\n",
    "#records_in_each_iteration = 400\n",
    "\n",
    "batch_size=256\n",
    "number_of_epocs_trained  = 0\n",
    "epochs_in_each_iteration = 10\n",
    "nb_epoch         = epochs_in_each_iteration\n",
    "records_in_each_iteration = 1024\n",
    "\n",
    "print(\"Toal epochs: \", len(X_train)/records_in_each_iteration*epochs_in_each_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_index:  0  end_index:  1024\n",
      "nb_epoch:  10  number_of_epocs_trained:  0\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 1/10\n",
      "1024/1024 [==============================] - 10s 9ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 2/10\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 3/10\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 4/10\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 5/10\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 6/10\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 7/10\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 8/10\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 9/10\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 10/10\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  1024  end_index:  2048\n",
      "nb_epoch:  20  number_of_epocs_trained:  10\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 11/20\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 12/20\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 13/20\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 14/20\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 15/20\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 16/20\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 17/20\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 18/20\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 19/20\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 20/20\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  2048  end_index:  3072\n",
      "nb_epoch:  30  number_of_epocs_trained:  20\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 21/30\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 22/30\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 23/30\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 24/30\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 25/30\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 26/30\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 27/30\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 28/30\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 29/30\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 30/30\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  3072  end_index:  4096\n",
      "nb_epoch:  40  number_of_epocs_trained:  30\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 31/40\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 32/40\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 33/40\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 34/40\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 35/40\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 36/40\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 37/40\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 38/40\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 39/40\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 40/40\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  4096  end_index:  5120\n",
      "nb_epoch:  50  number_of_epocs_trained:  40\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 41/50\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 42/50\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 43/50\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 44/50\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 45/50\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 46/50\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 47/50\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 48/50\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 49/50\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 50/50\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  5120  end_index:  6144\n",
      "nb_epoch:  60  number_of_epocs_trained:  50\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 51/60\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 52/60\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 53/60\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 54/60\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 55/60\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 56/60\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 57/60\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 58/60\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 59/60\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 60/60\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  6144  end_index:  7168\n",
      "nb_epoch:  70  number_of_epocs_trained:  60\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 61/70\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 62/70\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 63/70\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 64/70\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 65/70\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 66/70\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 67/70\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 68/70\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 69/70\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 70/70\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  7168  end_index:  8192\n",
      "nb_epoch:  80  number_of_epocs_trained:  70\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 71/80\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 72/80\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 73/80\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 74/80\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 75/80\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 76/80\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 77/80\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 78/80\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 79/80\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 80/80\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  8192  end_index:  9216\n",
      "nb_epoch:  90  number_of_epocs_trained:  80\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 81/90\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 82/90\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 83/90\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 84/90\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 85/90\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 86/90\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 87/90\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 88/90\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 89/90\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 90/90\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  9216  end_index:  10240\n",
      "nb_epoch:  100  number_of_epocs_trained:  90\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 91/100\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 92/100\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 93/100\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 94/100\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 95/100\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 96/100\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 97/100\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 98/100\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 99/100\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 100/100\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  10240  end_index:  11264\n",
      "nb_epoch:  110  number_of_epocs_trained:  100\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 101/110\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 102/110\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 103/110\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 104/110\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 105/110\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 106/110\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 107/110\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 108/110\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 109/110\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 110/110\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  11264  end_index:  12288\n",
      "nb_epoch:  120  number_of_epocs_trained:  110\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 111/120\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 112/120\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 113/120\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 114/120\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 115/120\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 116/120\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 117/120\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 118/120\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 119/120\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 120/120\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  12288  end_index:  13312\n",
      "nb_epoch:  130  number_of_epocs_trained:  120\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 121/130\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 122/130\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 123/130\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 124/130\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 125/130\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 126/130\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 127/130\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 128/130\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 129/130\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 130/130\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  13312  end_index:  14336\n",
      "nb_epoch:  140  number_of_epocs_trained:  130\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 131/140\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 132/140\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 133/140\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 134/140\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 135/140\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 136/140\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 137/140\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 138/140\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 139/140\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 140/140\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  14336  end_index:  15360\n",
      "nb_epoch:  150  number_of_epocs_trained:  140\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 141/150\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 142/150\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 143/150\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 144/150\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 145/150\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 146/150\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 147/150\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 148/150\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 149/150\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 150/150\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  15360  end_index:  16384\n",
      "nb_epoch:  160  number_of_epocs_trained:  150\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 151/160\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 152/160\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 153/160\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 154/160\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 155/160\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 156/160\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 157/160\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 158/160\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 159/160\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 160/160\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  16384  end_index:  17408\n",
      "nb_epoch:  170  number_of_epocs_trained:  160\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 161/170\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 162/170\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 163/170\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 164/170\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 165/170\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 166/170\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 167/170\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 168/170\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 169/170\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 170/170\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  17408  end_index:  18432\n",
      "nb_epoch:  180  number_of_epocs_trained:  170\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 171/180\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 172/180\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 173/180\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 174/180\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 175/180\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 176/180\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 177/180\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 178/180\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 179/180\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 180/180\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  18432  end_index:  19456\n",
      "nb_epoch:  190  number_of_epocs_trained:  180\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 181/190\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 182/190\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 183/190\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 184/190\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 185/190\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 186/190\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 187/190\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 188/190\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 189/190\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 190/190\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  19456  end_index:  20480\n",
      "nb_epoch:  200  number_of_epocs_trained:  190\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 191/200\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 192/200\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 193/200\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 194/200\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 195/200\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 196/200\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 197/200\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 198/200\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 199/200\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 200/200\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  20480  end_index:  21504\n",
      "nb_epoch:  210  number_of_epocs_trained:  200\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 201/210\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 202/210\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 203/210\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 204/210\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 205/210\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 206/210\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 207/210\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 208/210\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 209/210\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 210/210\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  21504  end_index:  22528\n",
      "nb_epoch:  220  number_of_epocs_trained:  210\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 211/220\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 212/220\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 213/220\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 214/220\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 215/220\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 216/220\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 217/220\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 218/220\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 219/220\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 220/220\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  22528  end_index:  23552\n",
      "nb_epoch:  230  number_of_epocs_trained:  220\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 221/230\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 222/230\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 223/230\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 224/230\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 225/230\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 226/230\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 227/230\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 228/230\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 229/230\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 230/230\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  23552  end_index:  24576\n",
      "nb_epoch:  240  number_of_epocs_trained:  230\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 231/240\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 232/240\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 233/240\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 234/240\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 235/240\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 236/240\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 237/240\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 238/240\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 239/240\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 240/240\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  24576  end_index:  25600\n",
      "nb_epoch:  250  number_of_epocs_trained:  240\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 241/250\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 242/250\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 243/250\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 244/250\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 245/250\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 246/250\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 247/250\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 248/250\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 249/250\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 250/250\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  25600  end_index:  26624\n",
      "nb_epoch:  260  number_of_epocs_trained:  250\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 251/260\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 252/260\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 253/260\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 254/260\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 255/260\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 256/260\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 257/260\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 258/260\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 259/260\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 260/260\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  26624  end_index:  27648\n",
      "nb_epoch:  270  number_of_epocs_trained:  260\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 261/270\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 262/270\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 263/270\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 264/270\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 265/270\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 266/270\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 267/270\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 268/270\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 269/270\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 270/270\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  27648  end_index:  28672\n",
      "nb_epoch:  280  number_of_epocs_trained:  270\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 271/280\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 272/280\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 273/280\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 274/280\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 275/280\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 276/280\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 277/280\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 278/280\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 279/280\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 280/280\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  28672  end_index:  29696\n",
      "nb_epoch:  290  number_of_epocs_trained:  280\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 281/290\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 282/290\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 283/290\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 284/290\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 285/290\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 286/290\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 287/290\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 288/290\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 289/290\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 290/290\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  29696  end_index:  30720\n",
      "nb_epoch:  300  number_of_epocs_trained:  290\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 291/300\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 292/300\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 293/300\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 294/300\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 295/300\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 296/300\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 297/300\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 298/300\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 299/300\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 300/300\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  30720  end_index:  31744\n",
      "nb_epoch:  310  number_of_epocs_trained:  300\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 301/310\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 302/310\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 303/310\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 304/310\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 305/310\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 306/310\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 307/310\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 308/310\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 309/310\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 310/310\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  31744  end_index:  32768\n",
      "nb_epoch:  320  number_of_epocs_trained:  310\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 311/320\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 312/320\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 313/320\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 314/320\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 315/320\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 316/320\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 317/320\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 318/320\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 319/320\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 320/320\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  32768  end_index:  33792\n",
      "nb_epoch:  330  number_of_epocs_trained:  320\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 321/330\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 322/330\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 323/330\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 324/330\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 325/330\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 326/330\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 327/330\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 328/330\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 329/330\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 330/330\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  33792  end_index:  34816\n",
      "nb_epoch:  340  number_of_epocs_trained:  330\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 331/340\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 332/340\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 333/340\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 334/340\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 335/340\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 336/340\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 337/340\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 338/340\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 339/340\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 340/340\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  34816  end_index:  35840\n",
      "nb_epoch:  350  number_of_epocs_trained:  340\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 341/350\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 342/350\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 343/350\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 344/350\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 345/350\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 346/350\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 347/350\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 348/350\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 349/350\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 350/350\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  35840  end_index:  36864\n",
      "nb_epoch:  360  number_of_epocs_trained:  350\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 351/360\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 352/360\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 353/360\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 354/360\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 355/360\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 356/360\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 357/360\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 358/360\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 359/360\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 360/360\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  36864  end_index:  37888\n",
      "nb_epoch:  370  number_of_epocs_trained:  360\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 361/370\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 362/370\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 363/370\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 364/370\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 365/370\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 366/370\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 367/370\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 368/370\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 369/370\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 370/370\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  37888  end_index:  38912\n",
      "nb_epoch:  380  number_of_epocs_trained:  370\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 371/380\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 372/380\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 373/380\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 374/380\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 375/380\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 376/380\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 377/380\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 378/380\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 379/380\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 380/380\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  38912  end_index:  39936\n",
      "nb_epoch:  390  number_of_epocs_trained:  380\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 381/390\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 382/390\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 383/390\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 384/390\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 385/390\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 386/390\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 387/390\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 388/390\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 389/390\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 390/390\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  39936  end_index:  40960\n",
      "nb_epoch:  400  number_of_epocs_trained:  390\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 391/400\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 392/400\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 393/400\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 394/400\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 395/400\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 396/400\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 397/400\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 398/400\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 399/400\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 400/400\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  40960  end_index:  41984\n",
      "nb_epoch:  410  number_of_epocs_trained:  400\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 401/410\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 402/410\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 403/410\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 404/410\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 405/410\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 406/410\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 407/410\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 408/410\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 409/410\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 410/410\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  41984  end_index:  43008\n",
      "nb_epoch:  420  number_of_epocs_trained:  410\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 411/420\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 412/420\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 413/420\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 414/420\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 415/420\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 416/420\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 417/420\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 418/420\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 419/420\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 420/420\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  43008  end_index:  44032\n",
      "nb_epoch:  430  number_of_epocs_trained:  420\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 421/430\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 422/430\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 423/430\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 424/430\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 425/430\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 426/430\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 427/430\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 428/430\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 429/430\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 430/430\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  44032  end_index:  45056\n",
      "nb_epoch:  440  number_of_epocs_trained:  430\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 431/440\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 432/440\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 433/440\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 434/440\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 435/440\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 436/440\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 437/440\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 438/440\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 439/440\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 440/440\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  45056  end_index:  46080\n",
      "nb_epoch:  450  number_of_epocs_trained:  440\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 441/450\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 442/450\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 443/450\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 444/450\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 445/450\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 446/450\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 447/450\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 448/450\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 449/450\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 450/450\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  46080  end_index:  47104\n",
      "nb_epoch:  460  number_of_epocs_trained:  450\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 451/460\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 452/460\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 453/460\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 454/460\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 455/460\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 456/460\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 457/460\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 458/460\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 459/460\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 460/460\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  47104  end_index:  48128\n",
      "nb_epoch:  470  number_of_epocs_trained:  460\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 461/470\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 462/470\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 463/470\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 464/470\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 465/470\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 466/470\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 467/470\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 468/470\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 469/470\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 470/470\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  48128  end_index:  49152\n",
      "nb_epoch:  480  number_of_epocs_trained:  470\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 471/480\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 472/480\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 473/480\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 474/480\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 475/480\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 476/480\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 477/480\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 478/480\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 479/480\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 480/480\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  49152  end_index:  50176\n",
      "nb_epoch:  490  number_of_epocs_trained:  480\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 481/490\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 482/490\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 483/490\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 484/490\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 485/490\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 486/490\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 487/490\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 488/490\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 489/490\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 490/490\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  50176  end_index:  51200\n",
      "nb_epoch:  500  number_of_epocs_trained:  490\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 491/500\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 492/500\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 493/500\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 494/500\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 495/500\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 496/500\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 497/500\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 498/500\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 499/500\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 500/500\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  51200  end_index:  52224\n",
      "nb_epoch:  510  number_of_epocs_trained:  500\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 501/510\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 502/510\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 503/510\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 504/510\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 505/510\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 506/510\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 507/510\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 508/510\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 509/510\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 510/510\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  52224  end_index:  53248\n",
      "nb_epoch:  520  number_of_epocs_trained:  510\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 511/520\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 512/520\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 513/520\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 514/520\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 515/520\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 516/520\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 517/520\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 518/520\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 519/520\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 520/520\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  53248  end_index:  54272\n",
      "nb_epoch:  530  number_of_epocs_trained:  520\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 521/530\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 522/530\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 523/530\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 524/530\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 525/530\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 526/530\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 527/530\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 528/530\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 529/530\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 530/530\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  54272  end_index:  55296\n",
      "nb_epoch:  540  number_of_epocs_trained:  530\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 531/540\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 532/540\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 533/540\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 534/540\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 535/540\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 536/540\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 537/540\n",
      "1024/1024 [==============================] - 9s 9ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 538/540\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 539/540\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 540/540\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  55296  end_index:  56320\n",
      "nb_epoch:  550  number_of_epocs_trained:  540\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 541/550\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 542/550\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 543/550\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 544/550\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 545/550\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 546/550\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 547/550\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 548/550\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 549/550\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 550/550\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  56320  end_index:  57344\n",
      "nb_epoch:  560  number_of_epocs_trained:  550\n",
      "Train on 1024 samples, validate on 7341 samples\n",
      "Epoch 551/560\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 552/560\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 553/560\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 554/560\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 555/560\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 556/560\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 557/560\n",
      "1024/1024 [==============================] - 9s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 558/560\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 559/560\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 560/560\n",
      "1024/1024 [==============================] - 8s 8ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "start_index:  57344  end_index:  58368\n",
      "nb_epoch:  570  number_of_epocs_trained:  560\n",
      "Train on 879 samples, validate on 7341 samples\n",
      "Epoch 561/570\n",
      "879/879 [==============================] - 8s 9ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 562/570\n",
      "879/879 [==============================] - 8s 9ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 563/570\n",
      "879/879 [==============================] - 8s 10ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 564/570\n",
      "879/879 [==============================] - 8s 10ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 565/570\n",
      "879/879 [==============================] - 8s 10ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 566/570\n",
      "879/879 [==============================] - 8s 9ms/step - loss: 0.0030 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 567/570\n",
      "879/879 [==============================] - 8s 10ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 568/570\n",
      "879/879 [==============================] - 8s 10ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 569/570\n",
      "879/879 [==============================] - 8s 9ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n",
      "Epoch 570/570\n",
      "879/879 [==============================] - 8s 9ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 0.0031 - val_acc: 0.9997\n"
     ]
    }
   ],
   "source": [
    "val_loss = []\n",
    "loss     = []\n",
    "\n",
    "for index in np.arange(0, len(X_train), records_in_each_iteration):\n",
    "    \n",
    "    print(\"start_index: \", index, \" end_index: \", index + records_in_each_iteration)\n",
    "    print(\"nb_epoch: \", nb_epoch, \" number_of_epocs_trained: \", number_of_epocs_trained )\n",
    "    \n",
    "    \n",
    "    X_train_ = X_train[index : index + records_in_each_iteration]    \n",
    "    Y_train_ = get_categorical(y_train[index : index + records_in_each_iteration], number_of_unique_classes)\n",
    "    \n",
    "    history = model.fit(X_train_, Y_train_, batch_size=batch_size, \\\n",
    "                        epochs        = nb_epoch,\\\n",
    "                        initial_epoch = number_of_epocs_trained,\n",
    "                        verbose=1, validation_data=(X_cv, Y_cv))\n",
    "    \n",
    "    val_loss = val_loss + list(history.history['val_loss'])\n",
    "    loss     = loss +  list(history.history['loss'])\n",
    "    \n",
    "    nb_epoch                = nb_epoch                + epochs_in_each_iteration\n",
    "    number_of_epocs_trained = number_of_epocs_trained + epochs_in_each_iteration\n",
    "    #print(\"val_loss: \", val_loss)\n",
    "    #print(\"loss: \", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_epoch = nb_epoch - epochs_in_each_iteration\n",
    "nb_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min, sys: 18.5 s, total: 1min 19s\n",
      "Wall time: 27.8 s\n",
      "test score: 0.0030723266063868125\n",
      "test accuracy: 0.9996532797813416\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%time score = model.evaluate(X_test, Y_test, verbose=0) \n",
    "print('test score:', score[0]) \n",
    "print('test accuracy:', score[1])\n",
    "    \n",
    "model_pretty_table.add_row([model_name, round(score[0]*100,2), round(score[1]*100,2)])\n",
    "    \n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\n",
    "\n",
    "# list of epoch numbers\n",
    "x = list(range(1,nb_epoch+1))\n",
    "\n",
    "#vy = history.history['val_loss']\n",
    "#ty = history.history['loss']\n",
    "\n",
    "vy = val_loss\n",
    "ty = loss\n",
    "\n",
    "plt_dynamic(fig, x, vy, ty, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n## **3 Layer LSTM Model**\\nmodel_name = '3 Layer LSTM Model'\\nnb_epoch=12\\nbatch_size=32\\nembedding_vecor_length = 32\\nmodel = Sequential()\\nmodel.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\\nmodel.add(LSTM(100, return_sequences=True))\\nmodel.add(LSTM(100, return_sequences=True))\\nmodel.add(LSTM(100))\\nmodel.add(Dense(1, activation='sigmoid'))\\ncompile_execute_model()\\n\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "## **3 Layer LSTM Model**\n",
    "model_name = '3 Layer LSTM Model'\n",
    "nb_epoch=12\n",
    "batch_size=32\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100, return_sequences=True))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "compile_execute_model()\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "_uuid": "b81200b16d37517d41585324a0660e82533fbb85"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+---------------+\n",
      "|       Model        | Test Score | Test Accuracy |\n",
      "+--------------------+------------+---------------+\n",
      "| 1 Layer LSTM Model |    0.31    |     99.97     |\n",
      "+--------------------+------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "print(model_pretty_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3adc7c98c2869b1193a6af8e225258a3ae1c31a3"
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c55d6204e52a0a275d79325c07dd0dfa3e894cd7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
